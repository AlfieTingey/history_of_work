{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of baseline_FLAIR_BERT.ipynb","provenance":[{"file_id":"1lvoCN5hpKs3UZdcpdrYhG-yVvDaob5Zs","timestamp":1582907254485}],"collapsed_sections":["Yu6s3YOf_C93","UDm3eqQwFahr","wiFHVnfH_Jpv","XSIE7d8HCTpi"],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4b96841840a44e86b08645b3b75906f1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d126a430a99644fb87344049230548a9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ba5c2b87d8ae4e1e9eb7ed9194ae3416","IPY_MODEL_0a67adfc6cfc429da13a6d12f29d049a"]}},"d126a430a99644fb87344049230548a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ba5c2b87d8ae4e1e9eb7ed9194ae3416":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5dc560e8d2d54de4886a7a2132d9c804","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":239836,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":239836,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d639c1bbc4e4082b924265dd5c15c18"}},"0a67adfc6cfc429da13a6d12f29d049a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e6aafdea3b4649f0a5a5b9e730b72546","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 240k/240k [00:00&lt;00:00, 431kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1fa237303b794c608b80e2539b96acd3"}},"5dc560e8d2d54de4886a7a2132d9c804":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5d639c1bbc4e4082b924265dd5c15c18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e6aafdea3b4649f0a5a5b9e730b72546":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1fa237303b794c608b80e2539b96acd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c9462ec34ee64cc187f87f1c91bf2299":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2497daee477e4b36931aa3bb5df99f2f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e67e0dd2a85d4a549dc95d3164b5c2ae","IPY_MODEL_7b5b68dbe630434e8e06325a9b65a437"]}},"2497daee477e4b36931aa3bb5df99f2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e67e0dd2a85d4a549dc95d3164b5c2ae":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_da0d680dc2924e4ca539f5dc1a675a90","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":593,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":593,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c8d6e09a7fe949399d539cc78ecb7441"}},"7b5b68dbe630434e8e06325a9b65a437":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_aa25452835f54fa2a2574566085cce04","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 593/593 [00:00&lt;00:00, 30.4kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_68dd63d2aa584f11a06c5259ceb722b6"}},"da0d680dc2924e4ca539f5dc1a675a90":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c8d6e09a7fe949399d539cc78ecb7441":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aa25452835f54fa2a2574566085cce04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"68dd63d2aa584f11a06c5259ceb722b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9e317bec7fef4d51bdc7d295bef95b1b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_04370d488e9e44808f5c91c9db3c6eaf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ab158a227c4f44a9ba2c9ba72bcc57fd","IPY_MODEL_1fc6e0367b5b4c3d86257dde5c5465aa"]}},"04370d488e9e44808f5c91c9db3c6eaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ab158a227c4f44a9ba2c9ba72bcc57fd":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9d0737d15e2041988805ce649760b77a","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":269752043,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":269752043,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_698a1ba37d844fefaae3ecd0bb7917c6"}},"1fc6e0367b5b4c3d86257dde5c5465aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a64a45871ae74d7e8ab33d736ba80851","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 270M/270M [00:23&lt;00:00, 11.5MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_522fd28f1e1a4a27b3e5a542e4b69d87"}},"9d0737d15e2041988805ce649760b77a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"698a1ba37d844fefaae3ecd0bb7917c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a64a45871ae74d7e8ab33d736ba80851":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"522fd28f1e1a4a27b3e5a542e4b69d87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fba1fa431a804ab7a77e915b68efbeb1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6e59407cc5664213a994dc2e3781bab6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_64387b6d27a8461fb5d23185a70a0982","IPY_MODEL_d06da2d7b8c042d0afc982e0c6b4aad9"]}},"6e59407cc5664213a994dc2e3781bab6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"64387b6d27a8461fb5d23185a70a0982":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_83b6e4fbbd16401dba38fdb4fde41915","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f50ee54dc16945f39f9cb59e99933189"}},"d06da2d7b8c042d0afc982e0c6b4aad9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1bde4abf7ae44771b52f57e9254a6b19","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 996k/996k [00:01&lt;00:00, 912kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_921359afd9c7448c81a2849e509691fd"}},"83b6e4fbbd16401dba38fdb4fde41915":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f50ee54dc16945f39f9cb59e99933189":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1bde4abf7ae44771b52f57e9254a6b19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"921359afd9c7448c81a2849e509691fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ea6163e1da294dc8acbdec1aa4b86c35":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a379e12d262a4403ad2f0b18e54db62f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ceabfcbac849473d8d58bf605c241bc4","IPY_MODEL_ee133487778f4637a7ec4ac51be5b303"]}},"a379e12d262a4403ad2f0b18e54db62f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ceabfcbac849473d8d58bf605c241bc4":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4442b4397aee403aada240deeaf4aead","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":569,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":569,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ac6eea2805994810a14551b7d5bd4a06"}},"ee133487778f4637a7ec4ac51be5b303":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0c6b3a76e5b04396a51c118e3c817474","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 569/569 [00:00&lt;00:00, 30.0kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_881782ce8ed94a278e7f22118d2e26bd"}},"4442b4397aee403aada240deeaf4aead":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ac6eea2805994810a14551b7d5bd4a06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0c6b3a76e5b04396a51c118e3c817474":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"881782ce8ed94a278e7f22118d2e26bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9cfa9179cb8b4dadb8721151b5cc81cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_091e049602f747629f9e3da9e7c6d287","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dfb9b7fca5f4438dab7d82b667d15d50","IPY_MODEL_431d059a41924975aa3816df767adda2"]}},"091e049602f747629f9e3da9e7c6d287":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dfb9b7fca5f4438dab7d82b667d15d50":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_77fb7040eb0644d38cfc2fd294e9e0f7","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":714314041,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":714314041,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c2a238b4b0ee41b9b3821e9e2c2cde0d"}},"431d059a41924975aa3816df767adda2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6a3103c20b4f40c5a769dd8cc8a83c31","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 714M/714M [01:02&lt;00:00, 11.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_580effb10f1f493cac3264f8f2989bcf"}},"77fb7040eb0644d38cfc2fd294e9e0f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c2a238b4b0ee41b9b3821e9e2c2cde0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6a3103c20b4f40c5a769dd8cc8a83c31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"580effb10f1f493cac3264f8f2989bcf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ff88446443bc4891a8d679d70beba514":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d12b0c3f80f24d7bae6827c93e54c3ba","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1309f05653c04780ba4b65b2e8fa1573","IPY_MODEL_27e52be88fe04e388a2a6d021476b5a8"]}},"d12b0c3f80f24d7bae6827c93e54c3ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1309f05653c04780ba4b65b2e8fa1573":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b5f6c81dd05942a58cf9f20861aa0577","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":760289,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":760289,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_59a111bc92564e659397c34151a4412d"}},"27e52be88fe04e388a2a6d021476b5a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_22b2cd3384c24b3484cf9b8eda9e7f28","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 760k/760k [00:00&lt;00:00, 833kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_942dccfcf08f45b7b1ab8f07dc850143"}},"b5f6c81dd05942a58cf9f20861aa0577":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"59a111bc92564e659397c34151a4412d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"22b2cd3384c24b3484cf9b8eda9e7f28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"942dccfcf08f45b7b1ab8f07dc850143":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5b7f648c4625456898f0c45360eef71e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0cf7cab2b002413fb909cb1c8c3524b3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3335663af6c7465084d16a6d158b2bf1","IPY_MODEL_9ad7b1948b364f31ad00084844a7a04e"]}},"0cf7cab2b002413fb909cb1c8c3524b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3335663af6c7465084d16a6d158b2bf1":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_92df70d50f6c4bde8683ca97ae8a8ff9","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":534,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":534,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_33a025a3ac744693a235ea6fe7c2c505"}},"9ad7b1948b364f31ad00084844a7a04e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_183a5cd2af134316b21956ead68b02b4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 534/534 [00:00&lt;00:00, 26.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_72be7a5b32804c8592d4c06d3734503e"}},"92df70d50f6c4bde8683ca97ae8a8ff9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"33a025a3ac744693a235ea6fe7c2c505":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"183a5cd2af134316b21956ead68b02b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"72be7a5b32804c8592d4c06d3734503e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1bd6f5a250454be0b3ee2da531039e74":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3453c6fc0e594e5b9dd06ab218ca2d52","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4102b8ff40a74ad194ca0ff1c87364cb","IPY_MODEL_9778676c574d4d18b0f49295bba5f6f9"]}},"3453c6fc0e594e5b9dd06ab218ca2d52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4102b8ff40a74ad194ca0ff1c87364cb":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c6213d0160b04fc8a2f6e98c6c58b2df","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":47376696,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":47376696,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_adb5a9eb74c741e1a6303de8d6bf1d31"}},"9778676c574d4d18b0f49295bba5f6f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e089d23e95094c0d8c699801ef8b0ff0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 47.4M/47.4M [00:04&lt;00:00, 9.87MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fae0cc67f0d74501a15a4f5c82ff6b2d"}},"c6213d0160b04fc8a2f6e98c6c58b2df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"adb5a9eb74c741e1a6303de8d6bf1d31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e089d23e95094c0d8c699801ef8b0ff0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fae0cc67f0d74501a15a4f5c82ff6b2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"omEQHVdOS61G"},"source":["# Coursework: Baseline Model\n","\n","This notebook takes you step by step to the implementation of a simple baseline model to get you started on the coursework. You have a section for the English-German task and another for English-Chinese. They are made to be standalone so feel free to check only one of the sections. However, as the tasks require slighlty different approaches, going through both sections could help you to get inspired for your chosen task, especially each task processes english in a slighlty different way.\n","\n","Enjoy!"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lweXud1Wpemd"},"source":["## A. English-German"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Yu6s3YOf_C93"},"source":["### Importing Data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"scs7ICZrPFcs","colab":{}},"source":["# Download and unzip the data\n","from os.path import exists\n","if not exists('ende_data.zip'):\n","    !wget -O ende_data.zip https://competitions.codalab.org/my/datasets/download/c748d2c0-d6be-4e36-9f12-ca0e88819c4d\n","    !unzip ende_data.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jPy_iwHnOSAZ","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1582900325460,"user_tz":0,"elapsed":771,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"42cbcce3-15d7-4c0a-b515-e000562f50a1"},"source":["# Check the files\n","import io\n","\n","#English-German\n","print(\"---EN-DE---\")\n","print()\n","\n","with open(\"./train.ende.src\", \"r\") as ende_src:\n","  print(\"Source: \",ende_src.readline())\n","with open(\"./train.ende.mt\", \"r\") as ende_mt:\n","  print(\"Translation: \",ende_mt.readline())\n","with open(\"./train.ende.scores\", \"r\") as ende_scores:\n","  print(\"Score: \",ende_scores.readline())\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["---EN-DE---\n","\n","Source:  José Ortega y Gasset visited Husserl at Freiburg in 1934.\n","\n","Translation:  1934 besuchte José Ortega y Gasset Husserl in Freiburg.\n","\n","Score:  1.1016968715664406\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UDm3eqQwFahr","colab_type":"text"},"source":["### Setting up GPU"]},{"cell_type":"code","metadata":{"id":"B2MuiNrrFZQf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1582900327179,"user_tz":0,"elapsed":542,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"03c85c8b-c406-46e0-9741-b701448d6277"},"source":["import numpy as np\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","# Fix GPU seeds\n","SEED = 9320\n","\n","if torch.cuda.is_available():\n","    torch.backends.cudnn.deterministic = True\n","    device = 'cuda:0'\n","else:\n","    device = 'cpu'\n","\n","print('Device is', device)\n","\n","\n","# we fix the seeds to get consistent results before every training\n","# loop in what follows\n","def fix_seed(seed=234):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","\n","fix_seed()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Device is cuda:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wiFHVnfH_Jpv"},"source":["### Computing Sentence Embeddings - FLAIR library\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"g05fv5GiSyQ4"},"source":["For this baseline model, we will simply use pre-trained GloVe embeddings via the Spacy module and compute the vector for each word and take the global mean for each sentence. We will do the same for both source and translation sentences. For chinese tokenization and embeddings we will have to find other tools.\n","\n","This is a very simplistic approach so feel free to be more creative and play around with how the sentence embeddings are computed for example ;)."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jcjZpNlra8TD"},"source":["GloVe embeddings do not support the Chinese language so in the section of the English-Chinese task we will have to download pretrained Chinese embeddings from word2vec repositories."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"96bRtBbuZLJe","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1582902164338,"user_tz":0,"elapsed":20852,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"7ad46f53-3ccc-496f-f3e0-4545b0ad1012"},"source":["import torch\n","!pip install flair\n","import flair\n","from flair.data import Sentence\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting flair\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/29/81e3c9a829ec50857c23d82560941625f6b42ce76ee7c56ea9529e959d18/flair-0.4.5-py3-none-any.whl (136kB)\n","\r\u001b[K     |██▍                             | 10kB 23.4MB/s eta 0:00:01\r\u001b[K     |████▉                           | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 40kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n","Collecting segtok>=1.5.7\n","  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.6)\n","Collecting mpld3==0.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n","\u001b[K     |████████████████████████████████| 798kB 42.1MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (2.6.1)\n","Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.1.3)\n","Requirement already satisfied: transformers>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from flair) (2.5.1)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.22.1)\n","Collecting pytest>=5.3.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/c0/34033b2df7718b91c667bd259d5ce632ec3720198b7068c0ba6f6104ff89/pytest-5.3.5-py3-none-any.whl (235kB)\n","\u001b[K     |████████████████████████████████| 235kB 56.1MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.4.0)\n","Collecting deprecated>=1.2.4\n","  Downloading https://files.pythonhosted.org/packages/f6/89/62912e01f3cede11edcc0abf81298e3439d9c06c8dce644369380ed13f6d/Deprecated-1.2.7-py2.py3-none-any.whl\n","Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n","Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n","Collecting bpemb>=0.2.9\n","  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n","Collecting sqlitedict>=1.6.0\n","  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n","Collecting langdetect\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n","\u001b[K     |████████████████████████████████| 1.0MB 47.6MB/s \n","\u001b[?25hRequirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->flair) (1.12.0)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.17.5)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n","Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (0.5.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (0.1.85)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (2.21.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (3.0.12)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (1.11.15)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (0.0.38)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (0.14.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (1.4.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (0.1.8)\n","Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.5.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (20.1)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (19.3.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (8.2.0)\n","Collecting pluggy<1.0,>=0.12\n","  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.8.1)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.11.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.10.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.4)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.9.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2.3->flair) (45.1.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->flair) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->flair) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->flair) (2019.11.28)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->flair) (0.9.4)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->flair) (0.3.3)\n","Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->flair) (1.14.15)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.3.0->flair) (7.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair) (3.0.0)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.1)\n","Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers>=2.3.0->flair) (0.15.2)\n","Building wheels for collected packages: segtok, mpld3, sqlitedict, langdetect\n","  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for segtok: filename=segtok-1.5.7-cp36-none-any.whl size=23258 sha256=94956d10e6be0af8b6d4db7bb1e39c1f5da5800b69b4d4016edf27d084793d0d\n","  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n","  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=97e3a6b41c12f59f4268ec613f83652842dba34291034a33f9b9a05d619de29b\n","  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n","  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=9c456d0c792682545fc9e70edd78f4d964f86aec99fd9b428e31894a6b603eb6\n","  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.7-cp36-none-any.whl size=993459 sha256=52a280a2256364815527d3b389651bd4686d07fa5362b2f2c402367544203568\n","  Stored in directory: /root/.cache/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n","Successfully built segtok mpld3 sqlitedict langdetect\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","Installing collected packages: segtok, mpld3, pluggy, pytest, deprecated, bpemb, sqlitedict, langdetect, flair\n","  Found existing installation: pluggy 0.7.1\n","    Uninstalling pluggy-0.7.1:\n","      Successfully uninstalled pluggy-0.7.1\n","  Found existing installation: pytest 3.6.4\n","    Uninstalling pytest-3.6.4:\n","      Successfully uninstalled pytest-3.6.4\n","Successfully installed bpemb-0.3.0 deprecated-1.2.7 flair-0.4.5 langdetect-1.0.7 mpld3-0.3 pluggy-0.13.1 pytest-5.3.5 segtok-1.5.7 sqlitedict-1.6.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4xFHULbu-cB-","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["4b96841840a44e86b08645b3b75906f1","d126a430a99644fb87344049230548a9","ba5c2b87d8ae4e1e9eb7ed9194ae3416","0a67adfc6cfc429da13a6d12f29d049a","5dc560e8d2d54de4886a7a2132d9c804","5d639c1bbc4e4082b924265dd5c15c18","e6aafdea3b4649f0a5a5b9e730b72546","1fa237303b794c608b80e2539b96acd3","c9462ec34ee64cc187f87f1c91bf2299","2497daee477e4b36931aa3bb5df99f2f","e67e0dd2a85d4a549dc95d3164b5c2ae","7b5b68dbe630434e8e06325a9b65a437","da0d680dc2924e4ca539f5dc1a675a90","c8d6e09a7fe949399d539cc78ecb7441","aa25452835f54fa2a2574566085cce04","68dd63d2aa584f11a06c5259ceb722b6","9e317bec7fef4d51bdc7d295bef95b1b","04370d488e9e44808f5c91c9db3c6eaf","ab158a227c4f44a9ba2c9ba72bcc57fd","1fc6e0367b5b4c3d86257dde5c5465aa","9d0737d15e2041988805ce649760b77a","698a1ba37d844fefaae3ecd0bb7917c6","a64a45871ae74d7e8ab33d736ba80851","522fd28f1e1a4a27b3e5a542e4b69d87","fba1fa431a804ab7a77e915b68efbeb1","6e59407cc5664213a994dc2e3781bab6","64387b6d27a8461fb5d23185a70a0982","d06da2d7b8c042d0afc982e0c6b4aad9","83b6e4fbbd16401dba38fdb4fde41915","f50ee54dc16945f39f9cb59e99933189","1bde4abf7ae44771b52f57e9254a6b19","921359afd9c7448c81a2849e509691fd","ea6163e1da294dc8acbdec1aa4b86c35","a379e12d262a4403ad2f0b18e54db62f","ceabfcbac849473d8d58bf605c241bc4","ee133487778f4637a7ec4ac51be5b303","4442b4397aee403aada240deeaf4aead","ac6eea2805994810a14551b7d5bd4a06","0c6b3a76e5b04396a51c118e3c817474","881782ce8ed94a278e7f22118d2e26bd","9cfa9179cb8b4dadb8721151b5cc81cd","091e049602f747629f9e3da9e7c6d287","dfb9b7fca5f4438dab7d82b667d15d50","431d059a41924975aa3816df767adda2","77fb7040eb0644d38cfc2fd294e9e0f7","c2a238b4b0ee41b9b3821e9e2c2cde0d","6a3103c20b4f40c5a769dd8cc8a83c31","580effb10f1f493cac3264f8f2989bcf","ff88446443bc4891a8d679d70beba514","d12b0c3f80f24d7bae6827c93e54c3ba","1309f05653c04780ba4b65b2e8fa1573","27e52be88fe04e388a2a6d021476b5a8","b5f6c81dd05942a58cf9f20861aa0577","59a111bc92564e659397c34151a4412d","22b2cd3384c24b3484cf9b8eda9e7f28","942dccfcf08f45b7b1ab8f07dc850143","5b7f648c4625456898f0c45360eef71e","0cf7cab2b002413fb909cb1c8c3524b3","3335663af6c7465084d16a6d158b2bf1","9ad7b1948b364f31ad00084844a7a04e","92df70d50f6c4bde8683ca97ae8a8ff9","33a025a3ac744693a235ea6fe7c2c505","183a5cd2af134316b21956ead68b02b4","72be7a5b32804c8592d4c06d3734503e","1bd6f5a250454be0b3ee2da531039e74","3453c6fc0e594e5b9dd06ab218ca2d52","4102b8ff40a74ad194ca0ff1c87364cb","9778676c574d4d18b0f49295bba5f6f9","c6213d0160b04fc8a2f6e98c6c58b2df","adb5a9eb74c741e1a6303de8d6bf1d31","e089d23e95094c0d8c699801ef8b0ff0","fae0cc67f0d74501a15a4f5c82ff6b2d"]},"executionInfo":{"status":"ok","timestamp":1582902668834,"user_tz":0,"elapsed":275901,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"d1f32d2f-4281-4a70-a656-3dee3d7d445e"},"source":["from flair.embeddings import WordEmbeddings\n","from flair.embeddings import CharacterEmbeddings\n","from flair.embeddings import StackedEmbeddings\n","from flair.embeddings import FlairEmbeddings\n","from flair.embeddings import BertEmbeddings\n","from flair.embeddings import ELMoEmbeddings\n","from flair.embeddings import FlairEmbeddings\n","from flair.embeddings import DocumentPoolEmbeddings\n","!pip install allennlp\n","\n","###########English Embeddings##########\n","# glove_embedding = WordEmbeddings('glove')\n","# character_embeddings = CharacterEmbeddings()\n","# bert_embedding = BertEmbedding()\n","elmo_embedding = ELMoEmbeddings()\n","\n","flair_forward_en  = FlairEmbeddings('news-forward-fast')\n","flair_backward_en = FlairEmbeddings('news-backward-fast')\n","\n","###########German Embeddings###############\n","\n","distillBERT_de = BertEmbeddings(bert_model_or_path=\"distilbert-base-german-cased\")\n","BERT_de =  BertEmbeddings(bert_model_or_path=\"bert-base-german-cased\")\n","\n","\n","#################MultiLingual Embeddings##########\n","# init Flair embeddings\n","flair_forward_embedding = FlairEmbeddings('multi-forward')\n","flair_backward_embedding = FlairEmbeddings('multi-backward')\n","\n","# init multilingual BERT\n","bert_embedding = BertEmbeddings('bert-base-multilingual-cased')\n","bert_embedding2 = BertEmbeddings(bert_model_or_path=\"albert-base-v2\")\n","\n","# #Stack some embeddings:\n","# stacked_embeddings = StackedEmbeddings(\n","#     embeddings=[flair_forward_embedding, flair_backward_embedding, bert_embedding])\n","\n","\n","\n","\n","# document_embeddings = DocumentPoolEmbeddings(\n","#     embeddings=[flair_forward_embedding, flair_backward_embedding, bert_embedding])\n","\n","# #sentence = Sentence('The grass is green .')\n","\n","# # just embed a sentence using the StackedEmbedding as you would with any single embedding.\n","# stacked_embeddings.embed(sentence)\n","\n","# # now check out the embedded tokens.\n","# for token in sentence:\n","#     print(token)\n","#     print(token.embedding)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting allennlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/bb/041115d8bad1447080e5d1e30097c95e4b66e36074277afce8620a61cee3/allennlp-0.9.0-py3-none-any.whl (7.6MB)\n","\u001b[K     |████████████████████████████████| 7.6MB 2.5MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.1)\n","Collecting unidecode\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n","\u001b[K     |████████████████████████████████| 245kB 56.5MB/s \n","\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.3)\n","Collecting word2number>=1.1\n","  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n","Collecting pytorch-pretrained-bert>=0.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\u001b[K     |████████████████████████████████| 133kB 53.8MB/s \n","\u001b[?25hCollecting jsonpickle\n","  Downloading https://files.pythonhosted.org/packages/7e/6b/fbb2d499b96861a18c1641f6fefe775110d3faba65c1524950e9ad64824a/jsonpickle-1.3-py2.py3-none-any.whl\n","Collecting conllu==1.3.1\n","  Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl\n","Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.0)\n","Collecting numpydoc>=0.8.0\n","  Downloading https://files.pythonhosted.org/packages/b0/70/4d8c3f9f6783a57ac9cc7a076e5610c0cc4a96af543cafc9247ac307fbfe/numpydoc-0.9.2.tar.gz\n","Collecting flaky\n","  Downloading https://files.pythonhosted.org/packages/fe/12/0f169abf1aa07c7edef4855cca53703d2e6b7ecbded7829588ac7e7e3424/flaky-3.6.1-py2.py3-none-any.whl\n","Collecting pytorch-transformers==1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/89/ad0d6bb932d0a51793eaabcf1617a36ff530dc9ab9e38f765a35dc293306/pytorch_transformers-1.1.0-py3-none-any.whl (158kB)\n","\u001b[K     |████████████████████████████████| 163kB 57.7MB/s \n","\u001b[?25hCollecting responses>=0.7\n","  Downloading https://files.pythonhosted.org/packages/d3/ab/d36ba96cc7e09ae337c9c7d52ab1cdce769802ff39a0295cce42ddaa5103/responses-0.10.11-py2.py3-none-any.whl\n","Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2018.9)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.17.5)\n","Collecting ftfy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/d8/5e877ac5e827eaa41a7ea8c0dc1d3042e05d7e337604dc2aedb854e7b500/ftfy-5.7.tar.gz (58kB)\n","\u001b[K     |████████████████████████████████| 61kB 8.7MB/s \n","\u001b[?25hRequirement already satisfied: spacy<2.2,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.1.9)\n","Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.3.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n","Collecting jsonnet>=0.10.0; sys_platform != \"win32\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/b8/a8588d4010f13716a324f55d23999259bad9db2320f4fe919a66b2f651f3/jsonnet-0.15.0.tar.gz (255kB)\n","\u001b[K     |████████████████████████████████| 256kB 57.6MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.28.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.11.15)\n","Collecting parsimonious>=0.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.6MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.1.3)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (5.3.5)\n","Collecting tensorboardX>=1.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n","\u001b[K     |████████████████████████████████| 204kB 58.7MB/s \n","\u001b[?25hCollecting flask-cors>=3.0.7\n","  Downloading https://files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.22.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.8.0)\n","Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.1)\n","Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.21.0)\n","Collecting overrides\n","  Downloading https://files.pythonhosted.org/packages/72/dd/ac49f9c69540d7e09210415801a05d0a54d4d0ca8401503c46847dacd3a0/overrides-2.8.0.tar.gz\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.0->allennlp) (2019.12.20)\n","Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (1.8.5)\n","Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (2.11.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.1.0->allennlp) (0.1.85)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from responses>=0.7->allennlp) (1.12.0)\n","Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent>=1.3.6->allennlp) (0.4.15)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp) (0.1.8)\n","Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.1)\n","Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (1.0.1)\n","Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (7.0.8)\n","Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.2.4)\n","Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.9.6)\n","Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.6.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (1.0.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.3)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.3.3)\n","Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (1.14.15)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.9.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.4.6)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.6.1)\n","Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.5.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (8.2.0)\n","Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.13.1)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.8.1)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (19.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (20.1)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.10.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp) (0.14.1)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.0.0)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (7.0)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.1.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2019.11.28)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.2.0)\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.0.0)\n","Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.2.0)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.7.12)\n","Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.8.0)\n","Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.1.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (45.1.0)\n","Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.15.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->numpydoc>=0.8.0->allennlp) (1.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->allennlp) (3.0.0)\n","Building wheels for collected packages: word2number, numpydoc, ftfy, jsonnet, parsimonious, overrides\n","  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for word2number: filename=word2number-1.1-cp36-none-any.whl size=5587 sha256=5f3a383bff8592c599aa29eb3e9b6a9dfd19b89ee8acc6306a1f7c179376f14e\n","  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n","  Building wheel for numpydoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for numpydoc: filename=numpydoc-0.9.2-cp36-none-any.whl size=31893 sha256=59eab082905c9bf765687ab15d68308ee38591eb1f6af2f1b78a9ef603a5ad53\n","  Stored in directory: /root/.cache/pip/wheels/96/f3/52/25c8e1f40637661d27feebc61dae16b84c7cdd93b8bc3d7486\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-5.7-cp36-none-any.whl size=44593 sha256=ea9849260a85870d9cb7b308880ccfa993df2ae736530a514aa6d939cf1a26c7\n","  Stored in directory: /root/.cache/pip/wheels/8e/da/59/6c8925d571aacade638a0f515960c21c0887af1bfe31908fbf\n","  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jsonnet: filename=jsonnet-0.15.0-cp36-cp36m-linux_x86_64.whl size=3320574 sha256=f9de9211801d0356bd45c919c051dc884b8325d2b1a4b6b946cc6f4c51c893a1\n","  Stored in directory: /root/.cache/pip/wheels/57/63/2e/da89cfe1ba08550bd7262d5d9c027edc313980c3b85b3b0a38\n","  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for parsimonious: filename=parsimonious-0.8.1-cp36-none-any.whl size=42712 sha256=9f74dcb3b225186af469ec3f2332c2cebc02b643e2669ae04a72d3016655ee04\n","  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-2.8.0-cp36-none-any.whl size=5609 sha256=05572180140be017a9185a5367926334776dc1778c324175715e148eb96e0062\n","  Stored in directory: /root/.cache/pip/wheels/df/f1/ba/eaf6cd7d284d2f257dc71436ce72d25fd3be5a5813a37794ab\n","Successfully built word2number numpydoc ftfy jsonnet parsimonious overrides\n","Installing collected packages: unidecode, word2number, pytorch-pretrained-bert, jsonpickle, conllu, numpydoc, flaky, pytorch-transformers, responses, ftfy, jsonnet, parsimonious, tensorboardX, flask-cors, overrides, allennlp\n","Successfully installed allennlp-0.9.0 conllu-1.3.1 flaky-3.6.1 flask-cors-3.0.8 ftfy-5.7 jsonnet-0.15.0 jsonpickle-1.3 numpydoc-0.9.2 overrides-2.8.0 parsimonious-0.8.1 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.1.0 responses-0.10.11 tensorboardX-2.0 unidecode-1.1.1 word2number-1.1\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 336/336 [00:00<00:00, 809469.35B/s]\n","100%|██████████| 374434792/374434792 [00:21<00:00, 17542670.07B/s]\n"],"name":"stderr"},{"output_type":"stream","text":["2020-02-28 15:08:11,098 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpmy9e4yq5\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 19689779/19689779 [00:03<00:00, 5033129.27B/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-02-28 15:08:16,151 copying /tmp/tmpmy9e4yq5 to cache at /root/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n","2020-02-28 15:08:16,170 removing temp file /tmp/tmpmy9e4yq5\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["2020-02-28 15:08:17,811 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpgxx98vcp\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 19689779/19689779 [00:03<00:00, 5667289.32B/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-02-28 15:08:22,439 copying /tmp/tmpgxx98vcp to cache at /root/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n","2020-02-28 15:08:22,459 removing temp file /tmp/tmpgxx98vcp\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b96841840a44e86b08645b3b75906f1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=239836, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9462ec34ee64cc187f87f1c91bf2299","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=593, style=ProgressStyle(description_width=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e317bec7fef4d51bdc7d295bef95b1b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=269752043, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","2020-02-28 15:08:59,347 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.3/lm-jw300-forward-v0.1.pt not found in cache, downloading to /tmp/tmpyk9gl8xj\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 172513724/172513724 [00:18<00:00, 9250363.23B/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-02-28 15:09:19,164 copying /tmp/tmpyk9gl8xj to cache at /root/.flair/embeddings/lm-jw300-forward-v0.1.pt\n","2020-02-28 15:09:19,347 removing temp file /tmp/tmpyk9gl8xj\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["2020-02-28 15:09:21,959 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.3/lm-jw300-backward-v0.1.pt not found in cache, downloading to /tmp/tmp_lsn2u7b\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 172513724/172513724 [00:19<00:00, 8839586.37B/s]"],"name":"stderr"},{"output_type":"stream","text":["2020-02-28 15:09:42,652 copying /tmp/tmp_lsn2u7b to cache at /root/.flair/embeddings/lm-jw300-backward-v0.1.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["2020-02-28 15:09:42,812 removing temp file /tmp/tmp_lsn2u7b\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fba1fa431a804ab7a77e915b68efbeb1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=995526, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea6163e1da294dc8acbdec1aa4b86c35","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=569, style=ProgressStyle(description_width=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9cfa9179cb8b4dadb8721151b5cc81cd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=714314041, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff88446443bc4891a8d679d70beba514","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=760289, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b7f648c4625456898f0c45360eef71e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=534, style=ProgressStyle(description_width=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1bd6f5a250454be0b3ee2da531039e74","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=47376696, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wnfq7691c9AN","colab_type":"code","colab":{}},"source":["document_embeddings_de = DocumentPoolEmbeddings(\n","    embeddings=[BERT_de])\n","\n","\n","document_embeddings_en  = DocumentPoolEmbeddings(\n","    embeddings=[elmo_embedding])\n","\n","# document_embeddings_de = DocumentPoolEmbeddings(\n","#     embeddings=[bert_embedding])\n","\n","\n","# document_embeddings_en  = DocumentPoolEmbeddings(\n","#     embeddings=[bert_embedding ])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zby8TQhgk8_q","colab_type":"code","colab":{}},"source":["from scipy.fftpack import dct\n","\n","#### DCT Pooling\n","def DCT_pooling(sent,k=2):\n","    '''\n","    Calculates sentence embedding by saving first k coefficients of DCT transform\n","    input: sent -> np array [B,N,D] B= Batch size N = number words, D = embedding dim\n","           k - how many coefficients to keep\n","    output: Sentence embedding\n","    '''\n","    \n","    num_words = sent.shape[0]\n","    embedding_dim = sent.shape[1]\n","    #DCT\n","    out = dct(sent,type=3,n=k, axis = 1)\n","    #reshape into row vector\n","    return out.reshape(-1,1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Om6kQX5bX2mB"},"source":["We can now write our functions that will return the average embeddings for a sentence."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nhT2I6WYavY4"},"source":["#### Pre-processing"]},{"cell_type":"code","metadata":{"id":"PGRSOAdkAiGy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1582902690945,"user_tz":0,"elapsed":6406,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"c2691b0c-976b-4149-9003-efa31048ba73"},"source":["!pip install nltk"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9IesVgRhBOR6","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1582902694799,"user_tz":0,"elapsed":2931,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"9181d467-81fa-4243-9b77-ab21a4ea2d13"},"source":["\n","from nltk.tokenize import RegexpTokenizer\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import wordnet\n","# from nltk.stem.cistem import Cistem\n","from nltk.corpus import stopwords\n","\n","#downloading stopwords from the nltk package\n","nltk.download('stopwords') #stopwords dictionary, run once\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","\n","stop_words_en = set(stopwords.words('english'))\n","stop_words_de = set(stopwords.words('german'))\n","\n","\n","tokenizer = RegexpTokenizer(r'\\w+')\n","lemmatizer = WordNetLemmatizer()\n","\n","\n","def nltk2wn_tag(nltk_tag):\n","  if nltk_tag.startswith('J'):\n","    return wordnet.ADJ\n","  elif nltk_tag.startswith('V'):\n","    return wordnet.VERB\n","  elif nltk_tag.startswith('N'):\n","    return wordnet.NOUN\n","  elif nltk_tag.startswith('R'):\n","    return wordnet.ADV\n","  else:          \n","    return None\n","\n","def lemmatize_sentence_en(sentence):\n","    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n","    wn_tagged = map(lambda x: (x[0], nltk2wn_tag(x[1])), nltk_tagged)\n","    res_words = []\n","    for word, tag in wn_tagged:\n","        if word not in stop_words_en:\n","            if tag is None:            \n","                res_words.append(word)\n","            else:\n","                res_words.append(lemmatizer.lemmatize(word, tag))\n","    return \" \".join(res_words)\n","\n","\n","\n","def lemmatize_sentence_de(sentence):\n","    '''\n","    input: sentence (list(tokens))\n","    return: lemmatized sentence list(tokens)\n","    '''\n","    stemmer = nltk.stem.cistem.Cistem()\n","    #Assumes tokenizing first\n","    \n","    return [stemmer.segment(token)[0] for token in sentence if token not in stop_words_de]\n","    \n","    \n","    \n","def tokenize_sentences(corpus):\n","\n","    return [tokenizer.tokenize(s) for s in corpus]\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"19gsNCgnW8ZT","colab":{}},"source":["import numpy as np\n","import spacy\n","import torch\n","from nltk import download\n","from nltk.corpus import stopwords\n","\n","#downloading stopwords from the nltk package\n","#download('stopwords') #stopwords dictionary, run once\n","\n","stop_words_en = set(stopwords.words('english'))\n","stop_words_de = set(stopwords.words('german'))\n","\n","def get_sentence_emb(line,nlp,lang):\n","  if lang == 'en':\n","    # text = line.lower()\n","    text = line\n","    l = lemmatize_sentence_en(text)\n","  elif lang == 'de':\n","    # text = line.lower()\n","    text = line\n","    # l = lemmatize_sentence_de(text)\n","    l=text\n","    l= ' '.join([word for word in l if word not in stop_words_de])\n","  \n","  sentence = Sentence(l)\n","  nlp.embed(sentence)\n","  return sentence.get_embedding()\n","\n","def get_embeddings(f,nlp,lang):\n","  file = open(f) \n","  lines = file.readlines() \n","  sentences_vectors  = []\n","  count=0\n","  for l in lines:\n","      vec = get_sentence_emb(l,nlp,lang)\n","      if vec is not None:\n","        # vec = np.mean(vec.cpu().detach().numpy())\n","        sentences_vectors.append(vec.cpu().detach().numpy())\n","      else:\n","        print(\"didn't work :\", l)\n","        sentences_vectors.append(0)\n","      if count % 100 == 0:\n","            print(count)\n","      count+=1\n","  return sentences_vectors\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NUKMgbo2sreI"},"source":["#### Getting Training and Validation Sets"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZXqZamIKs30T"},"source":["We will now run the code fo the English-German translations and getting our training and validation sets ready for the regression task.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GyJr7cIkQ3E8","colab":{}},"source":["# import spacy\n","\n","# nlp_de =spacy.load('de300')\n","# nlp_en =spacy.load('en300')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LwoUIDj0otbf","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1582903179042,"user_tz":0,"elapsed":10677,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"f904dd40-4c1d-48a0-a017-bc70f4877d8f"},"source":["import torch\n","\n","\n","#EN-DE files\n","de_train_src = get_embeddings(\"./train.ende.src\",document_embeddings_en,'en')\n","print(\"English dev Done\")\n","de_train_mt = get_embeddings(\"./train.ende.mt\",document_embeddings_de,'de')\n","print('German Done')\n","f_train_scores = open(\"./train.ende.scores\",'r')\n","de_train_scores = f_train_scores.readlines()\n","\n","de_val_src = get_embeddings(\"./dev.ende.src\",document_embeddings_en,'en')\n","de_val_mt = get_embeddings(\"./dev.ende.mt\",document_embeddings_de,'de')\n","f_val_scores = open(\"./dev.ende.scores\",'r')\n","de_val_scores = f_val_scores.readlines()\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","English dev Done\n","0\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n","5000\n","5100\n","5200\n","5300\n","5400\n","5500\n","5600\n","5700\n","5800\n","5900\n","6000\n","6100\n","6200\n","6300\n","6400\n","6500\n","6600\n","6700\n","6800\n","6900\n","German Done\n","0\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","0\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"U_K1CHl5VxiE","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1582903417909,"user_tz":0,"elapsed":1728,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"52204201-9175-4e64-d90a-e656b28d9d2b"},"source":["\n","#EN-DE\n","print(f\"Training mt: {len(de_train_mt)} Training src: {len(de_train_src)}\")\n","print()\n","print(f\"Validation mt: {len(de_val_mt)} Validation src: {len(de_val_src)}\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training mt: 7000 Training src: 7000\n","\n","Validation mt: 1000 Validation src: 1000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Px7ikaGoy9r0","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1582799273375,"user_tz":0,"elapsed":1059,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"baefdcb1-dce2-449d-fa45-a9828fe8d972"},"source":[""],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.1016968715664406\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pUPrCwMxFvpj","colab_type":"text"},"source":["### Computing embeddings - pre-trained BERT"]},{"cell_type":"code","metadata":{"id":"eHbroJV7FKEH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":416},"executionInfo":{"status":"ok","timestamp":1582903866748,"user_tz":0,"elapsed":13999,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"ffeead2d-2ea3-4d00-9697-00a1f695f7b0"},"source":["!pip install transformers\n","import random\n","\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","\n","from torchtext import data, datasets\n","from torch.utils.data import DataLoader, TensorDataset, sampler\n","\n","from transformers import BertTokenizer, BertConfig, BertModel, BertForSequenceClassification, AdamW\n","\n","\n","\n","class BERTembedd(nn.Module):\n","  def __init__(self, batch_size=64):\n","    super().__init__()\n","    self.english_BERT = BertModel.from_pretrained('bert-base-uncased')\n","    self.german_BERT = BertModel.from_pretrained('bert-base-german-cased')\n","    self.english_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","    self.german_tokenizer = BertTokenizer.from_pretrained('bert-base-german-cased')\n","    self.batch_size = batch_size\n","\n","\n","    if torch.cuda.is_available():\n","      torch.backends.cudnn.deterministic = True\n","      self.device = 'cuda:0'\n","    else:\n","      self.device = 'cpu'\n","\n","    print('Device is', self.device)\n","\n","  def prepare_data(self, f, lang, max_len=30):\n","    with open(f) as file:\n","      lines = file.readlines()\n","      if lang == \"en\":\n","        tokenizer = self.english_tokenizer\n","      elif lang == \"de\":\n","        tokenizer = self.german_tokenizer\n","      else:\n","        raise ValueError(\"lang must be either en or de\")\n","\n","    input_ids = torch.LongTensor(\n","      [tokenizer.encode(text, max_length=max_len, add_special_tokens=True, pad_to_max_length=True) for text in\n","       lines])\n","    tokenizer = None\n","\n","\n","    # Create attention masks\n","    attention_masks = []\n","    attention_masks = torch.zeros(input_ids.shape).long()\n","\n","    # Mask of the token is 0 if token_id is 0 (padding). mask is 1 otherwise.\n","    attention_masks[attention_masks != input_ids] = 1\n","\n","    # Create dataset and dataloader\n","    dataset = list(zip(input_ids, attention_masks))\n","    dataloader = DataLoader(dataset, batch_size=self.batch_size)\n","\n","\n","    return dataloader\n","\n","\n","  def get_embeddings(self, f, lang, pooling_fcn=torch.mean):\n","    d = self.prepare_data(f, lang)\n","\n","    if lang == \"en\":\n","      bert = self.english_BERT\n","    elif lang == \"de\":\n","      bert = self.german_BERT\n","    else:\n","      raise ValueError(\"lang must be de or en.\")\n","    bert = bert.to(self.device)\n","    bert.eval()\n","    with torch.no_grad():\n","      results = []\n","\n","      for x in d:\n","        sentences = x[0].to(self.device)\n","        masks = x[1].to(self.device)\n","        result = bert(input_ids=sentences, attention_mask=masks)[0] # -> (batch_size, sequence_length, hidden_size)\n","        # pooled = F.max_pool1d(result, result.shape[2]).squeeze() # -> (batch_size, sequence_length, 1)\n","        pooled = F.avg_pool1d(result, result.shape[2]).squeeze() # -> (batch_size, sequence_length, 1)\n","        if pooling_fcn is not None:\n","          sentence_vectors = pooling_fcn(pooled, 1)\n","        else:\n","          sentence_vectors = pooled\n","        # print(sentence_vectors)\n","        results += list(sentence_vectors.cpu().numpy())\n","\n","    return results\n","\n","\n","  def forward(self, f, lang, pooling_fcn=torch.mean):\n","    return self.get_embeddings(f, lang, pooling_fcn)\n","\n","\n","bertembedder = BERTembedd()\n","def get_bert_embeddings(f, lang, pooling_fcn=torch.mean):\n","  return bertembedder.forward(f, lang, pooling_fcn)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n","Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n","Device is cuda:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rb4YrhbcFvOu","colab_type":"text"},"source":["###### Bert embedding, getting training and validation with BERT:"]},{"cell_type":"code","metadata":{"id":"0K9iPfjYFh-n","colab_type":"code","colab":{}},"source":["#EN-DE files\n","de_train_src = get_bert_embeddings(\"./train.ende.src\",'en', pooling_fcn=torch.mean)\n","\n","de_train_mt = get_bert_embeddings(\"./train.ende.mt\",'de', pooling_fcn=torch.mean)\n","\n","f_train_scores = open(\"./train.ende.scores\",'r')\n","de_train_scores = f_train_scores.readlines()\n","\n","de_val_src = get_bert_embeddings(\"./dev.ende.src\",'en',pooling_fcn=torch.mean)\n","de_val_mt = get_bert_embeddings(\"./dev.ende.mt\",'de',pooling_fcn=torch.mean)\n","f_val_scores = open(\"./dev.ende.scores\",'r')\n","de_val_scores = f_val_scores.readlines()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XSIE7d8HCTpi"},"source":["### Pytorch NN Regressor\n","\n"]},{"cell_type":"markdown","metadata":{"id":"g-1j8PsLN6bY","colab_type":"text"},"source":["##### Prepare test and validation set vectors:"]},{"cell_type":"code","metadata":{"id":"TiWuTeqoHemB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1582904499456,"user_tz":0,"elapsed":1364,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"debea768-bb85-462e-8cb5-c5c054cea689"},"source":["#Put the features into a tesnor [B,D] - number sentences, embedding dim\n","import numpy as np\n","import torch\n","\n","num_samples = len(de_train_src)\n","num_dims = len(de_train_src[0]) * 2\n","X_train = torch.zeros((num_samples,num_dims),dtype=torch.float)\n","for i in range(len(de_train_src)):\n","  en_vec = de_train_src[i]\n","  de_vec = de_train_mt[i]\n","  vec = np.concatenate((en_vec,de_vec))\n","  vec = torch.tensor(vec,dtype=torch.float).squeeze()\n","\n","  X_train[i,:] = vec\n","\n","X_train_de = X_train\n","\n","\n","\n","# X_train= [np.array(de_train_src),np.array(de_train_mt)]\n","# X_train_de = np.array(X_train).transpose()\n","\n","\n","num_samples = len(de_val_src)\n","num_dims = len(de_val_src[0]) * 2\n","\n","X_val = torch.zeros((num_samples,num_dims),dtype=torch.float)\n","for i in range(len(de_val_src)):\n","  en_vec = de_val_src[i]\n","  de_vec = de_val_mt[i]\n","  vec = np.concatenate((en_vec,de_vec))\n","  vec = torch.tensor(vec,dtype=torch.float).squeeze()\n","  X_val[i,:] = vec\n","\n","X_val_de = X_val\n","\n","\n","# X_val = [np.array(de_val_src),np.array(de_val_mt)]\n","# X_val_de = np.array(X_val).transpose()\n","\n","#Scores\n","print(de_train_scores[0])\n","de_train_scores = np.array(de_train_scores, dtype=np.float)\n","train_scores = torch.tensor(de_train_scores).type(torch.float)\n","y_train_de =train_scores\n","\n","val_scores = np.array(de_val_scores,dtype=np.float)\n","val_scores = torch.tensor(val_scores, dtype=torch.float)\n","y_val_de =val_scores"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.1016968715664406\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3eoY14lNCTe3"},"source":["Pytorch FCL\n"]},{"cell_type":"code","metadata":{"id":"SvzW81Ezgak1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1582904504308,"user_tz":0,"elapsed":1987,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"a5ff22d5-829e-48ff-87c9-79d35b9925bc"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import datasets, transforms\n","\n","from scipy.stats.stats import pearsonr\n","\n","\n","# You should set a random seed to ensure that your results are reproducible.\n","torch.manual_seed(0)\n","use_cuda = torch.cuda.is_available()\n","device = torch.device('cuda' if use_cuda else 'cpu')\n","if use_cuda:\n","    torch.cuda.manual_seed(0)\n","    \n","print(\"Using GPU: {}\".format(use_cuda))\n","\n","class OneHiddenLayerMNISTClassifier(nn.Module):\n","    # Define entities containing model weights in the constructor.\n","    def __init__(self, n_hidden):\n","        super().__init__()\n","        self.linear1 = nn.Linear(\n","            in_features=num_dims, out_features=n_hidden, bias=True\n","        )\n","        self.linear2 = nn.Linear(\n","            in_features=n_hidden, out_features=200, bias=True\n","        )\n","\n","        self.linear3 = nn.Linear(\n","            in_features=200, out_features=100, bias=True\n","        )\n","\n","        self.linear4 = nn.Linear(\n","            in_features=100, out_features=1, bias=True\n","        )\n","\n","\n","    # Then, all you need to do is implement a `forward` method to define the\n","    # computation that takes place on the forward pass. A corresponding\n","    # `backward` method, which computes gradients, is automatically defined!\n","    def forward(self, inputs):\n","        h = self.linear1(inputs)\n","        h = F.tanh(h)\n","        h = self.linear2(h)\n","        h = F.tanh(h)\n","        h = self.linear3(h)\n","        h = F.tanh(h)\n","        h = self.linear4(h)\n","        \n","        return h\n","\n","\n","def train(model, train_loader, optimizer, epoch, log_interval=100):\n","    \"\"\"\n","    A utility function that performs a basic training loop.\n","\n","    For each batch in the training set, fetched using `train_loader`:\n","        - Zeroes the gradient used by `optimizer`\n","        - Performs forward pass through `model` on the given batch\n","        - Computes loss on batch\n","        - Performs backward pass\n","        - `optimizer` updates model parameters using computed gradient\n","\n","    Prints the training loss on the current batch every `log_interval` batches.\n","    \"\"\"\n","    for batch_idx, (inputs,targets) in enumerate(train_loader):\n","        # We need to send our batch to the device we are using. If this is not\n","        # it will default to using the CPU.\n","        inputs = inputs.to(device)\n","\n","        targets = targets.to(device)\n","        \n","        # Zeroes the gradient used by `optimizer`; NOTE: if this is not done,\n","        # then gradients will be accumulated across batches!\n","        optimizer.zero_grad()\n","\n","        # Performs forward pass through `model` on the given batch; equivalent\n","        # to `model.forward(inputs)`. Any information needed to compute\n","        # gradients is automatically thanks to autograd running under the hood.\n","        outputs = model(inputs)\n","\n","        # Computes loss on batch; `F.mse_loss` computes the mean squared error \n","        #loss on batch.\n"," \n","        loss =  F.mse_loss(outputs.squeeze(),targets)\n","\n","        # Performs backward pass; steps backward through the computation graph,\n","        # computing the gradient of the loss wrt model parameters.\n","        loss.backward()\n","\n","        # `optimizer` updates model parameters using computed gradient.\n","        optimizer.step()\n","\n","        # Prints the training loss on the current batch every `log_interval`\n","        # batches.\n","        if batch_idx % log_interval == 0:\n","            print(\n","                \"Train Epoch: {:02d} -- Batch: {:03d} -- Loss: {:.4f}\".format(\n","                    epoch,\n","                    batch_idx,\n","                    # Calling `loss.item()` returns the scalar loss as a Python\n","                    # number.\n","                    loss.item(),\n","                )\n","            )\n","\n","\n","def val(model, test_loader):\n","    \"\"\"\n","    A utility function to compute the loss and accuracy on a test set by\n","    iterating through the test set using the provided `test_loader` and\n","    accumulating the loss and accuracy on each batch.\n","    \"\"\"\n","    test_loss = 0.0\n","    count =0\n","    test_pearson = 0\n","    # You should use the `torch.no_grad()` context when you want to perform a\n","    # forward pass but do not need gradients. This effectively disables\n","    # autograd and results in fewer resources being used to perform the forward\n","    # pass (since information needed to compute gradients is not logged).\n","    with torch.no_grad():\n","        for inputs, targets in test_loader:\n","            inputs = inputs.to(device)\n","            targets = targets.to(device)\n","            # We use `reduction=\"sum\"` to aggregate losses across batches using\n","            # summation instead of taking the mean - we will take the mean at\n","            # the end once we have accumulated all the losses.\n","            outputs = model(inputs)\n","            test_loss += F.mse_loss(outputs.squeeze(), targets, reduction=\"sum\").item()\n","            # pred = outputs.argmax(dim=1, keepdim=True)\n","            pred = outputs\n","            # correct += pred.eq(targets.view_as(pred)).sum().item()\n","   \n","            test_pearson =  pearsonr(targets.cpu(), outputs.squeeze().cpu())\n","            print(test_pearson)\n","            count +=1\n","\n","    pearson_score = test_pearson\n","    print(f'Pearson score: {pearson_score[0]}')\n","\n","\n","\n","def test(model,input):\n","    with torch.no_grad():\n","      return model(input)\n","    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using GPU: True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CaQblN_NgvYZ","colab_type":"text"},"source":["Create data loaders\n"]},{"cell_type":"code","metadata":{"id":"B_fuPsYAguWt","colab_type":"code","colab":{}},"source":[" # Create dataloaders\n","from torch.utils.data import TensorDataset\n","# train_dataset = TensorDataset(X_train, y_train)\n","\n","\n","\n","train_loader = DataLoader(TensorDataset(X_train_de, y_train_de), batch_size=128, shuffle=True)\n","test_loader = DataLoader(TensorDataset(X_val_de, y_val_de), batch_size=1000, shuffle=False)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k59OhSXIhCAb","colab_type":"text"},"source":["Training the model"]},{"cell_type":"code","metadata":{"id":"wayI9jpdhBLx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1582905305254,"user_tz":0,"elapsed":23573,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"472adbd9-24bb-4ab8-f2c8-abc77e770577"},"source":["model = OneHiddenLayerMNISTClassifier(n_hidden=100).to(device)\n","\n","# Create instance of optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","# Train-test loop\n","for epoch in range(150):\n","    train(model, train_loader, optimizer, epoch)\n","\n","val(model, test_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Train Epoch: 00 -- Batch: 000 -- Loss: 1.1142\n","Train Epoch: 01 -- Batch: 000 -- Loss: 0.9789\n","Train Epoch: 02 -- Batch: 000 -- Loss: 0.7936\n","Train Epoch: 03 -- Batch: 000 -- Loss: 0.9088\n","Train Epoch: 04 -- Batch: 000 -- Loss: 0.6705\n","Train Epoch: 05 -- Batch: 000 -- Loss: 0.4876\n","Train Epoch: 06 -- Batch: 000 -- Loss: 0.3257\n","Train Epoch: 07 -- Batch: 000 -- Loss: 0.9002\n","Train Epoch: 08 -- Batch: 000 -- Loss: 0.7124\n","Train Epoch: 09 -- Batch: 000 -- Loss: 0.7570\n","Train Epoch: 10 -- Batch: 000 -- Loss: 0.7919\n","Train Epoch: 11 -- Batch: 000 -- Loss: 1.2568\n","Train Epoch: 12 -- Batch: 000 -- Loss: 0.5428\n","Train Epoch: 13 -- Batch: 000 -- Loss: 0.2917\n","Train Epoch: 14 -- Batch: 000 -- Loss: 0.4030\n","Train Epoch: 15 -- Batch: 000 -- Loss: 0.8317\n","Train Epoch: 16 -- Batch: 000 -- Loss: 0.8784\n","Train Epoch: 17 -- Batch: 000 -- Loss: 0.8211\n","Train Epoch: 18 -- Batch: 000 -- Loss: 0.6996\n","Train Epoch: 19 -- Batch: 000 -- Loss: 0.6248\n","Train Epoch: 20 -- Batch: 000 -- Loss: 0.3495\n","Train Epoch: 21 -- Batch: 000 -- Loss: 1.0022\n","Train Epoch: 22 -- Batch: 000 -- Loss: 0.4603\n","Train Epoch: 23 -- Batch: 000 -- Loss: 1.2052\n","Train Epoch: 24 -- Batch: 000 -- Loss: 0.3125\n","Train Epoch: 25 -- Batch: 000 -- Loss: 0.5046\n","Train Epoch: 26 -- Batch: 000 -- Loss: 0.4843\n","Train Epoch: 27 -- Batch: 000 -- Loss: 0.4527\n","Train Epoch: 28 -- Batch: 000 -- Loss: 1.3685\n","Train Epoch: 29 -- Batch: 000 -- Loss: 1.0550\n","Train Epoch: 30 -- Batch: 000 -- Loss: 0.5742\n","Train Epoch: 31 -- Batch: 000 -- Loss: 0.3233\n","Train Epoch: 32 -- Batch: 000 -- Loss: 0.4216\n","Train Epoch: 33 -- Batch: 000 -- Loss: 0.2992\n","Train Epoch: 34 -- Batch: 000 -- Loss: 0.4948\n","Train Epoch: 35 -- Batch: 000 -- Loss: 0.8538\n","Train Epoch: 36 -- Batch: 000 -- Loss: 0.7897\n","Train Epoch: 37 -- Batch: 000 -- Loss: 0.8743\n","Train Epoch: 38 -- Batch: 000 -- Loss: 0.4402\n","Train Epoch: 39 -- Batch: 000 -- Loss: 0.4633\n","Train Epoch: 40 -- Batch: 000 -- Loss: 0.8484\n","Train Epoch: 41 -- Batch: 000 -- Loss: 0.6578\n","Train Epoch: 42 -- Batch: 000 -- Loss: 0.5163\n","Train Epoch: 43 -- Batch: 000 -- Loss: 0.4995\n","Train Epoch: 44 -- Batch: 000 -- Loss: 0.9608\n","Train Epoch: 45 -- Batch: 000 -- Loss: 0.6757\n","Train Epoch: 46 -- Batch: 000 -- Loss: 0.8232\n","Train Epoch: 47 -- Batch: 000 -- Loss: 0.4630\n","Train Epoch: 48 -- Batch: 000 -- Loss: 0.9209\n","Train Epoch: 49 -- Batch: 000 -- Loss: 0.3811\n","Train Epoch: 50 -- Batch: 000 -- Loss: 0.4081\n","Train Epoch: 51 -- Batch: 000 -- Loss: 0.6913\n","Train Epoch: 52 -- Batch: 000 -- Loss: 0.4795\n","Train Epoch: 53 -- Batch: 000 -- Loss: 0.6896\n","Train Epoch: 54 -- Batch: 000 -- Loss: 0.6982\n","Train Epoch: 55 -- Batch: 000 -- Loss: 0.8778\n","Train Epoch: 56 -- Batch: 000 -- Loss: 0.9980\n","Train Epoch: 57 -- Batch: 000 -- Loss: 0.8491\n","Train Epoch: 58 -- Batch: 000 -- Loss: 1.5680\n","Train Epoch: 59 -- Batch: 000 -- Loss: 1.3908\n","Train Epoch: 60 -- Batch: 000 -- Loss: 0.3881\n","Train Epoch: 61 -- Batch: 000 -- Loss: 0.4584\n","Train Epoch: 62 -- Batch: 000 -- Loss: 0.7513\n","Train Epoch: 63 -- Batch: 000 -- Loss: 0.4018\n","Train Epoch: 64 -- Batch: 000 -- Loss: 1.2586\n","Train Epoch: 65 -- Batch: 000 -- Loss: 0.3527\n","Train Epoch: 66 -- Batch: 000 -- Loss: 0.8077\n","Train Epoch: 67 -- Batch: 000 -- Loss: 1.1122\n","Train Epoch: 68 -- Batch: 000 -- Loss: 0.3746\n","Train Epoch: 69 -- Batch: 000 -- Loss: 0.4821\n","Train Epoch: 70 -- Batch: 000 -- Loss: 0.6060\n","Train Epoch: 71 -- Batch: 000 -- Loss: 0.9836\n","Train Epoch: 72 -- Batch: 000 -- Loss: 0.7030\n","Train Epoch: 73 -- Batch: 000 -- Loss: 0.4008\n","Train Epoch: 74 -- Batch: 000 -- Loss: 0.4103\n","Train Epoch: 75 -- Batch: 000 -- Loss: 0.7881\n","Train Epoch: 76 -- Batch: 000 -- Loss: 0.8365\n","Train Epoch: 77 -- Batch: 000 -- Loss: 0.5972\n","Train Epoch: 78 -- Batch: 000 -- Loss: 0.5898\n","Train Epoch: 79 -- Batch: 000 -- Loss: 0.6489\n","Train Epoch: 80 -- Batch: 000 -- Loss: 0.6025\n","Train Epoch: 81 -- Batch: 000 -- Loss: 1.2813\n","Train Epoch: 82 -- Batch: 000 -- Loss: 0.4310\n","Train Epoch: 83 -- Batch: 000 -- Loss: 0.3795\n","Train Epoch: 84 -- Batch: 000 -- Loss: 1.0596\n","Train Epoch: 85 -- Batch: 000 -- Loss: 0.7584\n","Train Epoch: 86 -- Batch: 000 -- Loss: 0.7448\n","Train Epoch: 87 -- Batch: 000 -- Loss: 0.2497\n","Train Epoch: 88 -- Batch: 000 -- Loss: 0.5873\n","Train Epoch: 89 -- Batch: 000 -- Loss: 0.7443\n","Train Epoch: 90 -- Batch: 000 -- Loss: 0.3966\n","Train Epoch: 91 -- Batch: 000 -- Loss: 0.4126\n","Train Epoch: 92 -- Batch: 000 -- Loss: 1.4365\n","Train Epoch: 93 -- Batch: 000 -- Loss: 0.6970\n","Train Epoch: 94 -- Batch: 000 -- Loss: 1.4079\n","Train Epoch: 95 -- Batch: 000 -- Loss: 0.4929\n","Train Epoch: 96 -- Batch: 000 -- Loss: 0.8597\n","Train Epoch: 97 -- Batch: 000 -- Loss: 0.2113\n","Train Epoch: 98 -- Batch: 000 -- Loss: 0.6293\n","Train Epoch: 99 -- Batch: 000 -- Loss: 0.7269\n","Train Epoch: 100 -- Batch: 000 -- Loss: 0.8402\n","Train Epoch: 101 -- Batch: 000 -- Loss: 0.8068\n","Train Epoch: 102 -- Batch: 000 -- Loss: 0.4231\n","Train Epoch: 103 -- Batch: 000 -- Loss: 0.8231\n","Train Epoch: 104 -- Batch: 000 -- Loss: 0.8256\n","Train Epoch: 105 -- Batch: 000 -- Loss: 0.9589\n","Train Epoch: 106 -- Batch: 000 -- Loss: 0.6465\n","Train Epoch: 107 -- Batch: 000 -- Loss: 0.4723\n","Train Epoch: 108 -- Batch: 000 -- Loss: 0.3385\n","Train Epoch: 109 -- Batch: 000 -- Loss: 0.5659\n","Train Epoch: 110 -- Batch: 000 -- Loss: 0.4097\n","Train Epoch: 111 -- Batch: 000 -- Loss: 0.6898\n","Train Epoch: 112 -- Batch: 000 -- Loss: 0.3070\n","Train Epoch: 113 -- Batch: 000 -- Loss: 0.9029\n","Train Epoch: 114 -- Batch: 000 -- Loss: 0.4125\n","Train Epoch: 115 -- Batch: 000 -- Loss: 0.5547\n","Train Epoch: 116 -- Batch: 000 -- Loss: 0.3809\n","Train Epoch: 117 -- Batch: 000 -- Loss: 0.4098\n","Train Epoch: 118 -- Batch: 000 -- Loss: 0.5529\n","Train Epoch: 119 -- Batch: 000 -- Loss: 0.5476\n","Train Epoch: 120 -- Batch: 000 -- Loss: 0.7644\n","Train Epoch: 121 -- Batch: 000 -- Loss: 0.3858\n","Train Epoch: 122 -- Batch: 000 -- Loss: 0.8002\n","Train Epoch: 123 -- Batch: 000 -- Loss: 0.7146\n","Train Epoch: 124 -- Batch: 000 -- Loss: 0.4054\n","Train Epoch: 125 -- Batch: 000 -- Loss: 0.9404\n","Train Epoch: 126 -- Batch: 000 -- Loss: 0.3602\n","Train Epoch: 127 -- Batch: 000 -- Loss: 0.4448\n","Train Epoch: 128 -- Batch: 000 -- Loss: 1.0479\n","Train Epoch: 129 -- Batch: 000 -- Loss: 0.5288\n","Train Epoch: 130 -- Batch: 000 -- Loss: 0.6884\n","Train Epoch: 131 -- Batch: 000 -- Loss: 0.5267\n","Train Epoch: 132 -- Batch: 000 -- Loss: 0.7998\n","Train Epoch: 133 -- Batch: 000 -- Loss: 0.7603\n","Train Epoch: 134 -- Batch: 000 -- Loss: 0.4725\n","Train Epoch: 135 -- Batch: 000 -- Loss: 0.8410\n","Train Epoch: 136 -- Batch: 000 -- Loss: 0.2317\n","Train Epoch: 137 -- Batch: 000 -- Loss: 0.4878\n","Train Epoch: 138 -- Batch: 000 -- Loss: 0.8333\n","Train Epoch: 139 -- Batch: 000 -- Loss: 0.8360\n","Train Epoch: 140 -- Batch: 000 -- Loss: 0.3596\n","Train Epoch: 141 -- Batch: 000 -- Loss: 0.9713\n","Train Epoch: 142 -- Batch: 000 -- Loss: 0.2795\n","Train Epoch: 143 -- Batch: 000 -- Loss: 0.6962\n","Train Epoch: 144 -- Batch: 000 -- Loss: 0.4557\n","Train Epoch: 145 -- Batch: 000 -- Loss: 1.1339\n","Train Epoch: 146 -- Batch: 000 -- Loss: 1.2585\n","Train Epoch: 147 -- Batch: 000 -- Loss: 0.6272\n","Train Epoch: 148 -- Batch: 000 -- Loss: 0.8085\n","Train Epoch: 149 -- Batch: 000 -- Loss: 0.6385\n","(0.06397509183766084, 0.04311317263530701)\n","Pearson score: 0.06397509183766084\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AlF9jpCDguuV","colab_type":"text"},"source":["### Other regressors"]},{"cell_type":"markdown","metadata":{"id":"jBgh9xS0PTzD","colab_type":"text"},"source":["Putting data in list"]},{"cell_type":"code","metadata":{"id":"tyfL6g5WPW34","colab_type":"code","colab":{}},"source":["#Put the features into a list\n","import numpy as np\n","\n","X_train= [np.array(de_train_src),np.array(de_train_mt)]\n","X_train_de = np.array(X_train).transpose()\n","\n","X_val = [np.array(de_val_src),np.array(de_val_mt)]\n","X_val_de = np.array(X_val).transpose()\n","\n","#Scores\n","train_scores = np.array(de_train_scores).astype(float)\n","y_train_de =train_scores\n","\n","val_scores = np.array(de_val_scores).astype(float)\n","y_val_de =val_scores"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WwFOE0_LPbL4","colab_type":"text"},"source":["Define RMSE"]},{"cell_type":"code","metadata":{"id":"ze_fZHuDPlrD","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def rmse(predictions, targets):\n","    return np.sqrt(((predictions - targets) ** 2).mean())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IerDa2251swL"},"source":["#### SVM"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"exHbrWtq14jm"},"source":["SVM have many parameters such as the kernel and the regularizating constant C. Here we will use C = 1 and compare kernels. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QiHCkGUgsJ8r","colab":{"base_uri":"https://localhost:8080/","height":225},"executionInfo":{"status":"ok","timestamp":1582905805050,"user_tz":0,"elapsed":10935,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"543b61da-761a-4dd0-96ca-ec4e77d397fa"},"source":["from sklearn.svm import SVR\n","from scipy.stats.stats import pearsonr\n","\n","for k in ['linear','poly','rbf','sigmoid']:\n","    clf_t = SVR(kernel=k)\n","    clf_t.fit(X_train_de, y_train_de)\n","    print(k)\n","    predictions = clf_t.predict(X_val_de)\n","    pearson = pearsonr(y_val_de, predictions)\n","    print(f'RMSE: {rmse(predictions,y_val_de)} Pearson {pearson[0]}')\n","    print()\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["linear\n","RMSE: 0.8815523248077068 Pearson 0.02316592901063899\n","\n","poly\n","RMSE: 0.881270949278876 Pearson 0.025748763501295843\n","\n","rbf\n","RMSE: 0.8811243881929659 Pearson 0.026738971503697792\n","\n","sigmoid\n","RMSE: 23.256236575094878 Pearson 0.014059164328044008\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qg9YSBUG1zaL"},"source":["#### Random Tree Forest"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VOld4zbmsOGL","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1582905890564,"user_tz":0,"elapsed":67454,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"40aeead9-cc31-41c7-a525-18d448103ccc"},"source":["# Import the model we are using\n","\n","from sklearn.ensemble import RandomForestRegressor\n","\n","for n in [100,500,1000,1500]:\n","\n","  rf = RandomForestRegressor(n_estimators = n, random_state = 666)\n","\n","  rf.fit(X_train_de, y_train_de);\n","\n","\n","  predictions = rf.predict(X_val_de)\n","\n","  pearson = pearsonr(y_val_de, predictions)\n","  print('RMSE:', rmse(predictions,y_val_de))\n","  print(f\"Pearson {pearson[0]} for n_estimators = {n}\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RMSE: 0.9171844096424996\n","Pearson 0.020763124093085897 for n_estimators = 100\n","RMSE: 0.9174139364155368\n","Pearson 0.007309205571025664 for n_estimators = 500\n","RMSE: 0.9165907358012123\n","Pearson 0.009060574412041517 for n_estimators = 1000\n","RMSE: 0.9168888726567898\n","Pearson 0.007834303184429967 for n_estimators = 1500\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oaqYBaKVfUpp","colab_type":"text"},"source":["Here is a regressor using KerasRegressor. Makes use of Neural networks and hyper parameter searching. \n"]},{"cell_type":"code","metadata":{"id":"8V30C4Sc69eY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":506},"executionInfo":{"status":"ok","timestamp":1582905906009,"user_tz":0,"elapsed":8851,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"2a87f491-cc97-4339-f8aa-ffd1f62885e6"},"source":["### Keras Regressor using Neural Networks ####\n","\n","# This is a neural network regressor that we built using keras\n","\n","# Import necessary packages\n","from sklearn import linear_model\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasRegressor\n","\n","# Create random seed to replicate results\n","seed = 1\n","\n","# Create lists that we can use for hyper-parameter search\n","activation = ['sigmoid', 'tanh'] # activation functions used\n","layer_size_1 = [80, 100] # first layer size\n","layer_size_2 = [40, 100] # second layer size\n","optimizer = ['adam', 'sgd'] # two optimizers used\n","batch_size = [32,64] # different batch sizes\n","\n","# Conduct hyper-parameter search using 'for loops' \n","\n","for item in activation:\n","  for size_1 in layer_size_1:\n","    for size_2 in layer_size_2:\n","      for optim in optimizer:\n","        for batch in batch_size:\n","\n","          # Build the neural network architecture. We add three layers into the neural network\n","          # and assign activation functions. \n","          def baseline_model():\n","              model = Sequential()\n","              model.add(Dense(40, input_dim=2, activation='tanh'))\n","              model.add(Dense(10, activation = 'tanh'))\n","              model.add(Dense(1, activation = 'linear'))\n","              model.compile(loss='mse', optimizer='adam')\n","              return model\n","\n","          # Create the estimator using the KerasRegressor function from Keras and our\n","          # model architecutre\n","          estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=32, verbose=False, validation_split = 0.2)\n","\n","          # train the model with the training data\n","          estimator.fit(X_train_de, y_train_de);\n","\n","          # Predict the model on the validation/test data\n","          predictions = estimator.predict(X_val_de)\n","\n","          # compute pearson score for each hyper-parameter selection\n","          pearson = pearsonr(y_val_de, predictions)\n","          print('RMSE:', rmse(predictions,y_val_de))\n","          print(f\"Pearson {pearson[0]}, activation = {item}, size_1 = {size_1}, size_2 = {size_2}, optim = {optim}, batch size = {batch}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","RMSE: 0.8645205190554102\n","Pearson -0.004148206212801797\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LjKaqYNNfdnj","colab_type":"text"},"source":["Here I test out a Kernel Ridge Regressor. Similar to SVR with slight differences.\n"]},{"cell_type":"code","metadata":{"id":"2trZRJByAcVC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1582905932510,"user_tz":0,"elapsed":13916,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"ec4f9a46-18c9-4e79-9c29-b890c1b97f6c"},"source":["### Kernel Ridge Regressor ####\n","\n","# import necessary packages to apply KernelRidge Regressor\n","from sklearn.kernel_ridge import KernelRidge\n","\n","# Create list for kernel such that we can perform hyper-parameter search.\n","for k in ['linear','poly','rbf','sigmoid']:\n","  # Create Regressor\n","  kr = KernelRidge(alpha = 0.2, kernel = k)\n","\n","  # Train the model on the trianing data\n","  kr.fit(X_train_de, y_train_de);\n","\n","  # Predict outcome for the validation/test data\n","  predictions = kr.predict(X_val_de)\n","\n","  # Compute and pring pearson value for each hyper-parameter selection\n","  pearson = pearsonr(y_val_de, predictions)\n","  print('RMSE:', rmse(predictions,y_val_de))\n","  print(f\"Pearson score for KernelRidge Regression: {pearson[0]} for kernel = {k}\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RMSE: 0.8638932073906487\n","Pearson score for KernelRidge Regression: 0.03584678337960797 for kernel = linear\n","RMSE: 0.8638899984186302\n","Pearson score for KernelRidge Regression: 0.03318011280305015 for kernel = poly\n","RMSE: 0.8638932466690457\n","Pearson score for KernelRidge Regression: 0.035468538582623894 for kernel = rbf\n","RMSE: 0.8638994229750283\n","Pearson score for KernelRidge Regression: 0.0387287287343936 for kernel = sigmoid\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Qpv0rLpiflJr","colab_type":"text"},"source":["The next regressor I test is the Passive Aggressive Regressor from sklearn."]},{"cell_type":"code","metadata":{"id":"Xs49RXhaBtdS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1582905944309,"user_tz":0,"elapsed":654,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"441d9971-0812-4b14-b5e9-a3131c81cb56"},"source":["### Passive Aggressive Regressor ###\n","\n","# import necessary packages for the Passive Aggressive regressor\n","from sklearn.linear_model import PassiveAggressiveRegressor\n","\n","# create values for max iterations used for hyper-parameter search\n","max_iter = [100, 200, 300]\n","\n","# conduct hyper-parameter search\n","for value in max_iter:\n","\n","  # create regressor from library\n","  clf = PassiveAggressiveRegressor(max_iter = value, random_state = 0)\n","\n","  # fit the model to the training data\n","  clf.fit(X_train_de, y_train_de)\n","\n","  # predict outcomes for validation/test data\n","  clf.predict(X_val_de)\n","\n","  # Print Pearson score for each hyper-parameter selection\n","  pearson = pearsonr(y_val_de, predictions)\n","  print('RMSE:', rmse(predictions,y_val_de))\n","  print(f\"Pearson score for PA Regression: {pearson[0]}, max iteration is {value}\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RMSE: 0.8638994229750283\n","Pearson score for PA Regression: 0.0387287287343936\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1kmCMJmIfrfI","colab_type":"text"},"source":["I also try the TheilSen regressor from sklearn. "]},{"cell_type":"code","metadata":{"id":"Zw1UyTZEFtsX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1582905957571,"user_tz":0,"elapsed":3236,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"82ad2e4e-b9f8-430f-d68f-59fc39510545"},"source":["### TheilSen Regressor ###\n","\n","# Import necessary packages for the TheilSen Regressor\n","from sklearn.linear_model import TheilSenRegressor\n","\n","# create values for max iterations used for hyper-parameter search\n","max_iter = [100, 200, 300]\n","\n","# conduct hyper-parameter search\n","for value in max_iter:\n","\n","  # create regressor from library\n","  tsr = TheilSenRegressor(max_iter = value, random_state = 0)\n","\n","  # fit the model to the training data\n","  tsr.fit(X_train_de, y_train_de)\n","\n","  # predict outcomes for validation/test data\n","  tsr.predict(X_val_de)\n","\n","  pearson = pearsonr(y_val_de, predictions)\n","  print('RMSE:', rmse(predictions,y_val_de))\n","  print(f\"Pearson score for TSR Regression: {pearson[0]}, max iteration = {value}\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RMSE: 0.8638994229750283\n","Pearson score for TSR Regression: 0.0387287287343936\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"k1l1cERjf0ir","colab_type":"text"},"source":["Next I test the Gradient Boostin regressor from sklearn."]},{"cell_type":"code","metadata":{"id":"V1_e__2thJgI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":434},"executionInfo":{"status":"ok","timestamp":1582905973898,"user_tz":0,"elapsed":9164,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"45c18b97-6687-4745-e407-9d54b2678fe1"},"source":["# import necessary package from sklearn\n","\n","from sklearn import ensemble\n","\n","#### Gradient Boosting Regressor ####\n","\n","# create lists for hyper-parameter search. Change learning rate, \n","# max depth and n_estimator value\n","\n","for lr in [0.001, 0.0005]:\n","  for max_depth in [1,2]:\n","    for n_estimator in [200,500]:\n","\n","      # Put hyper-parameters in parameter dictionary\n","      params = {'n_estimators': n_estimator, 'max_depth': max_depth, 'min_samples_split': 2,\n","                'learning_rate': lr, 'loss': 'ls'}\n","\n","      # Create Gradient Boosting Regressor\n","      clf = ensemble.GradientBoostingRegressor(**params)\n","\n","      # Train the model on the training data\n","      clf.fit(X_train_de, y_train_de)\n","\n","      # Predict outcomes on validation data\n","      predictions = clf.predict(X_val_de)\n","\n","      # Compute and print pearson score for each hyper-parameter evaluation\n","      pearson = pearsonr(y_val_de, predictions)\n","      print('RMSE:', rmse(predictions,y_val_de))\n","      print(f\"Pearson Gradient Boosting Regressor: {pearson[0]} with lr = {lr}, max_depth = {max_depth}, n_estimator = {n_estimator}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n","  warnings.warn(PearsonRConstantInputWarning())\n"],"name":"stderr"},{"output_type":"stream","text":["RMSE: 0.8639040160750084\n","Pearson Gradient Boosting Regressor: nan with lr = 0.001, max_depth = 1, n_estimator = 200\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n","  warnings.warn(PearsonRConstantInputWarning())\n"],"name":"stderr"},{"output_type":"stream","text":["RMSE: 0.8639071947381184\n","Pearson Gradient Boosting Regressor: nan with lr = 0.001, max_depth = 1, n_estimator = 500\n","RMSE: 0.8637188063364276\n","Pearson Gradient Boosting Regressor: 0.04102789914741822 with lr = 0.001, max_depth = 2, n_estimator = 200\n","RMSE: 0.8636124658386475\n","Pearson Gradient Boosting Regressor: 0.03539659808635272 with lr = 0.001, max_depth = 2, n_estimator = 500\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n","  warnings.warn(PearsonRConstantInputWarning())\n"],"name":"stderr"},{"output_type":"stream","text":["RMSE: 0.8639027377528806\n","Pearson Gradient Boosting Regressor: nan with lr = 0.0005, max_depth = 1, n_estimator = 200\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n","  warnings.warn(PearsonRConstantInputWarning())\n"],"name":"stderr"},{"output_type":"stream","text":["RMSE: 0.863904610309668\n","Pearson Gradient Boosting Regressor: nan with lr = 0.0005, max_depth = 1, n_estimator = 500\n","RMSE: 0.8637630797945611\n","Pearson Gradient Boosting Regressor: 0.050526866274125365 with lr = 0.0005, max_depth = 2, n_estimator = 200\n","RMSE: 0.863702224295285\n","Pearson Gradient Boosting Regressor: 0.03788722301305035 with lr = 0.0005, max_depth = 2, n_estimator = 500\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ckuKf4_Wf5nU","colab_type":"text"},"source":["Here I use an MLP regressor from sklearn and a pipeline which is used to create a hyper parameter search. So far the best results have come from this of about 0.772."]},{"cell_type":"code","metadata":{"id":"tVC4sO6MhWiC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"status":"ok","timestamp":1582906041052,"user_tz":0,"elapsed":10569,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"21ced3d8-9022-4e35-fbd1-d0489fcd524d"},"source":["# MLP regressor.... using neural networks to predict labels #\n","\n","# import necessary packages from sklearn library for MLP regressor.\n","from sklearn.pipeline import make_pipeline\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.preprocessing import StandardScaler\n","\n","# Create list of scores so we can keep track of best Pearson score\n","list_of_scores = []\n","\n","# initalise hyper-parameter search\n","for hidden_layer_size in [(100),(100,100)]:\n","  for activation in ['relu','logistic','tanh']:\n","    for learning_rate in [0.001]:\n","      for solver in ['adam','sgd']:\n","        \n","        # use pipeline to create MLP regressor\n","        mlp = make_pipeline(StandardScaler(),\n","                            MLPRegressor(hidden_layer_sizes=hidden_layer_size,\n","                                        tol=1e-2, max_iter=500, random_state=0,early_stopping = False, learning_rate_init = learning_rate, activation = activation,solver = solver))\n","\n","\n","        # Train model on the training data\n","        mlp.fit(X_train_de, y_train_de)\n","\n","        # Evaluate model on training/validation data\n","        predictions = mlp.predict(X_val_de)\n","\n","        # Compute and print Pearson score for each hyper-parameter evaluation\n","        pearson = pearsonr(y_val_de, predictions)\n","\n","        list_of_scores.append(pearson[0])\n","\n","        print('RMSE:', rmse(predictions,y_val_de))\n","        print(f\"mlp Regression Pearson: {pearson[0]} for hidden_layer_size = {hidden_layer_size}, activation = {activation}, learning_rate = {learning_rate}, solver = {solver}\")\n","\n","# Print highest pearson score\n","highest_pearson = max(list_of_scores)\n","print(f'highest pearson score is {highest_pearson}')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RMSE: 0.8627738173589881\n","mlp Regression Pearson: 0.04871467066315298 for hidden_layer_size = 100, activation = relu, learning_rate = 0.001, solver = adam\n","RMSE: 0.8640966324587362\n","mlp Regression Pearson: 0.01666724969930131 for hidden_layer_size = 100, activation = relu, learning_rate = 0.001, solver = sgd\n","RMSE: 0.8636248006571877\n","mlp Regression Pearson: 0.03147185820197343 for hidden_layer_size = 100, activation = logistic, learning_rate = 0.001, solver = adam\n","RMSE: 0.8638408517197841\n","mlp Regression Pearson: 0.023327163080269296 for hidden_layer_size = 100, activation = logistic, learning_rate = 0.001, solver = sgd\n","RMSE: 0.8660894003533958\n","mlp Regression Pearson: 0.00520628517702393 for hidden_layer_size = 100, activation = tanh, learning_rate = 0.001, solver = adam\n","RMSE: 0.8638373858946172\n","mlp Regression Pearson: 0.01875658845426788 for hidden_layer_size = 100, activation = tanh, learning_rate = 0.001, solver = sgd\n","RMSE: 0.8650959316659498\n","mlp Regression Pearson: 0.018673115547737158 for hidden_layer_size = (100, 100), activation = relu, learning_rate = 0.001, solver = adam\n","RMSE: 0.8642289942250485\n","mlp Regression Pearson: 0.012904834313285204 for hidden_layer_size = (100, 100), activation = relu, learning_rate = 0.001, solver = sgd\n","RMSE: 0.8636781550697766\n","mlp Regression Pearson: 0.02633209157850886 for hidden_layer_size = (100, 100), activation = logistic, learning_rate = 0.001, solver = adam\n","RMSE: 0.8644449283818799\n","mlp Regression Pearson: 0.03274380596571168 for hidden_layer_size = (100, 100), activation = logistic, learning_rate = 0.001, solver = sgd\n","RMSE: 0.864093667158875\n","mlp Regression Pearson: 0.022504387796655527 for hidden_layer_size = (100, 100), activation = tanh, learning_rate = 0.001, solver = adam\n","RMSE: 0.8642290880472124\n","mlp Regression Pearson: 0.008519186136853428 for hidden_layer_size = (100, 100), activation = tanh, learning_rate = 0.001, solver = sgd\n","highest pearson score is 0.04871467066315298\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3BAhlHdBgNh8","colab_type":"text"},"source":["Here is a neural network regressor which I create from scratch using pytorch. I have included a small hyper parameter search. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"G9puD_0zkC2c"},"source":["### Writing Results"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oQvvIhPDkUnR"},"source":["Here is our function to write the scores into a txt file. We can follow the <Method> <ID> <SCORE> template but having only the scores will work too."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LN3NtkF4kPxw","colab":{}},"source":["import os\n","\n","def writeScores(method_name,scores):\n","    fn = \"predictions.txt\"\n","    print(\"\")\n","    with open(fn, 'w') as output_file:\n","        for idx,x in enumerate(scores):\n","            #out =  metrics[idx]+\":\"+str(\"{0:.2f}\".format(x))+\"\\n\"\n","            #print(out)\n","            output_file.write(f\"{x}\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HzTj3-iW28wY","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FVss_RLBkFei","colab":{}},"source":["#EN-DE\n","\n","import numpy as np\n","import torch\n","\n","# de_test_src = get_embeddings(\"./test.ende.src\",document_embeddings_en,'en')\n","# de_test_mt = get_embeddings(\"./test.ende.mt\",document_embeddings_de,'de')\n","\n","de_test_src = get_bert_embeddings(\"./test.ende.src\",'en',pooling_fcn=None)\n","\n","de_test_mt = get_bert_embeddings(\"./test.ende.mt\",'de',pooling_fcn=None)\n","\n","# mlp instead of svr\n","\n","# mlp = make_pipeline(StandardScaler(),\n","#                             MLPRegressor(hidden_layer_sizes=(100,100),\n","#                                         tol=1e-2, max_iter=500, random_state=0,early_stopping = False, learning_rate_init = 0.001, activation = 'tanh',solver = 'adam'))\n","# mlp.fit(X_train_de, y_train_de)\n","\n","# predictions_de = mlp.predict(X_val_de)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Xkoc4FHiTJR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1582905492960,"user_tz":0,"elapsed":1301,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"ac02c6c7-b0f1-4be6-871c-0e1e2be01672"},"source":["num_samples = len(de_test_src)\n","num_dims = len(de_test_src[0]) * 2\n","X_test = torch.zeros((num_samples,num_dims),dtype=torch.float)\n","for i in range(len(de_test_src)):\n","  en_vec = de_test_src[i]\n","  de_vec = de_test_mt[i]\n","  vec = np.concatenate((en_vec,de_vec))\n","  vec = torch.tensor(vec,dtype=torch.float).squeeze()\n","  X_test[i,:] = vec\n","\n","X_test_de = X_test\n","\n","\n","#Predict\n","\n","predictions = test(model, X_test.to(device))\n","\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XWnNUR0Gku_9","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1582905545557,"user_tz":0,"elapsed":3636,"user":{"displayName":"Toby Godwin","photoUrl":"","userId":"13332404558939469664"}},"outputId":"21e16bb9-b79f-44bc-a00f-8a2913e49227"},"source":["from google.colab import files\n","from zipfile import ZipFile\n","\n","\n","writeScores(\"korbi_bert\",predictions.squeeze())\n","\n","with ZipFile(\"en-de_kbert.zip\",\"w\") as newzip:\n","\tnewzip.write(\"predictions.txt\")\n"," \n","files.download('en-de_kbert.zip') "],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AXoDKREdhVBn","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}